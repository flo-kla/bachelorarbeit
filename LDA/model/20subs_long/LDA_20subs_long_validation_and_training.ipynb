{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import math\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "# Plotting tools\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "#load training Data\n",
    "with open('../../../data/Datasets/20subs_long/idocnade/training.csv', newline='') as csvfile1:\n",
    "    data_train = pd.read_csv(csvfile1,  names=[\"Label\", \"Text\"])\n",
    "    train_fold = data_train.dropna(subset=['Text'])   \n",
    "\n",
    "#load validation Data\n",
    "with open('../../../data/Datasets/20subs_long/idocnade/validation.csv', newline='') as csvfile2:\n",
    "    data_val = pd.read_csv(csvfile2,  names=[\"Label\", \"Text\"])\n",
    "    val_fold = data_val.dropna(subset=['Text'])     \n",
    "    \n",
    "frames = [train_fold,val_fold]\n",
    "train_data = pd.concat(frames)\n",
    "\n",
    "\n",
    "#load testing Data\n",
    "with open('../../../data/Datasets/20subs_long/idocnade/test.csv', newline='') as csvfile3:\n",
    "    data_test = pd.read_csv(csvfile3,  names=[\"Label\", \"Text\"])  \n",
    "    test_data = data_test.dropna(subset=['Text'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1050ea8bfa7542b5853b35c15334ffe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=67.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flokla/anaconda3/lib/python3.8/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  m_lr_i = np.log(numerator / denominator)\n",
      "/home/flokla/anaconda3/lib/python3.8/site-packages/gensim/topic_coherence/indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#perform cross-validation for alpha, beta, k\n",
    "hyperparameter_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "alpha = [0.1,0.3,0.5,0.7,1]\n",
    "beta = [0.1,0.3,0.5,0.7,1]\n",
    "\n",
    "\n",
    "#data prep\n",
    "dictionary = gensim.corpora.Dictionary(train_fold[\"Text\"].str.split())\n",
    "corpus_train = [dictionary.doc2bow(text.split()) for index,text in train_fold[\"Text\"].iteritems()]\n",
    "corpus_val = [dictionary.doc2bow(text.split()) for index,text in val_fold[\"Text\"].iteritems()]\n",
    "texts = [[dictionary[word_id] for word_id, freq in doc] for doc in corpus_val]\n",
    "\n",
    "for k in tqdm(range(1, 200, 3)):\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    lda_model = gensim.models.LdaMulticore(corpus=corpus_train,\n",
    "                                                           id2word = dictionary, \n",
    "                                                           num_topics = k, \n",
    "                                                           alpha=a,\n",
    "                                                           eta=b,\n",
    "                                                           workers=15)\n",
    "                    # Coherence\n",
    "                    coherence_model_small = gensim.models.coherencemodel.CoherenceModel(model=lda_model,\n",
    "                                                                                        topn = 10,\n",
    "                                                                                        texts = texts,\n",
    "                                                                                        coherence='c_v')\n",
    "                    coherence_model_large = gensim.models.coherencemodel.CoherenceModel(model=lda_model,\n",
    "                                                                                        topn = 20,\n",
    "                                                                                        texts = texts,\n",
    "                                                                                        coherence='c_v')\n",
    "                    coherence1 = coherence_model_small.get_coherence()\n",
    "                    coherence2 = coherence_model_large.get_coherence()\n",
    "                    c_v = (coherence1+coherence2)/2\n",
    "                    hyperparameter_results['Topics'].append(k)\n",
    "                    hyperparameter_results['Alpha'].append(a)\n",
    "                    hyperparameter_results['Beta'].append(b)\n",
    "                    hyperparameter_results['Coherence'].append(c_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../LDA/model/20subs_long/hyperparameter_tuning.', 'w') as f:\n",
    "    print(hyperparameter_results, file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best hyperparameter\n",
    "a = 0.1\n",
    "b = 1\n",
    "k = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best lda model with optimal alpha beta for k=*\n",
    "dictionary = gensim.corpora.Dictionary(train_data[\"Text\"].str.split())\n",
    "corpus_train = [dictionary.doc2bow(text.split()) for index,text in train_data[\"Text\"].iteritems()]\n",
    "lda_model_k_star = gensim.models.LdaMulticore(corpus=corpus_train,\n",
    "                                                           id2word = dictionary, \n",
    "                                                           num_topics = k, \n",
    "                                                           alpha=a,\n",
    "                                                           eta=b,\n",
    "                                                           workers=15)\n",
    "lda_model_k_star.save('../../../LDA/model/20subs_long/lda.model_with_optimal_k/lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best lda model with optimal alpha beta for k=20\n",
    "lda_model_k_20 = gensim.models.LdaMulticore(corpus=corpus_train,\n",
    "                                                           id2word = dictionary, \n",
    "                                                           num_topics = 20, \n",
    "                                                           alpha=a,\n",
    "                                                           eta=b,\n",
    "                                                           workers=15)\n",
    "lda_model_k_20.save('../../../LDA/model/20subs_long/lda.model_with_k20/lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best lda model with optimal alpha beta for k=50\n",
    "lda_model_k_50 = gensim.models.LdaMulticore(corpus=corpus_train,\n",
    "                                                           id2word = dictionary, \n",
    "                                                           num_topics = 50, \n",
    "                                                           alpha=a,\n",
    "                                                           eta=b,\n",
    "                                                           workers=15)\n",
    "lda_model_k_50.save('../../../LDA/model/20subs_long/lda.model_with_k50/lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best lda model with optimal alpha beta for k=100\n",
    "lda_model_k_100 = gensim.models.LdaMulticore(corpus=corpus_train,\n",
    "                                                           id2word = dictionary, \n",
    "                                                           num_topics = 100, \n",
    "                                                           alpha=a,\n",
    "                                                           eta=b,\n",
    "                                                           workers=15)\n",
    "lda_model_k_100.save('../../../LDA/model/20subs_long/lda.model_with_k100/lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best lda model with optimal alpha beta for k=200\n",
    "lda_model_k_200 = gensim.models.LdaMulticore(corpus=corpus_train,\n",
    "                                                           id2word = dictionary, \n",
    "                                                           num_topics = 200, \n",
    "                                                           alpha=a,\n",
    "                                                           eta=b,\n",
    "                                                           workers=15)\n",
    "lda_model_k_200.save('../../../LDA/model/20subs_long/lda.model_with_k200/lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coherence for top10 and top20 topics words per topic, average across all topics, save highest and lowest c_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform logistisc regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print some topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       d need stay probably negative voltage supply o...\n",
       "1       confused developer work grant web designer nee...\n",
       "2            d like express mod team allow post thank lot\n",
       "3       fun thing loose capacity function level requir...\n",
       "4                                               thank try\n",
       "                              ...                        \n",
       "9435                  read require tuner min subscription\n",
       "9436    pound powder primer brass medical bill dollar ...\n",
       "9437                                       oppose vehicle\n",
       "9438    feed beast come malady live stop drag decent b...\n",
       "9439                             work right hold consider\n",
       "Name: Text, Length: 9351, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
