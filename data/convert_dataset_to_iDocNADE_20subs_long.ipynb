{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/processed/preprocess/test.csv\")\n",
    "train = pd.read_csv(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/processed/preprocess/training.csv\")\n",
    "frames=[test,train]\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/vocabbuilder.txt\",\"w\",encoding='utf-8')\n",
    "for index,row in data.iterrows():\n",
    "    #print(row[\"text\"])\n",
    "    if row[\"text\"] == \"\":\n",
    "        continue\n",
    "    #text = \" \".join(str(row[\"text\"]))\n",
    "    f.write(str(row[\"text\"])+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build vocab file and calculate appearence-fraction of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/flokla/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def get_frac_dist(token_list):\n",
    "    '''\n",
    "    Computes frequency count and fraction of individual words in a list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    token_list : list\n",
    "        List of all (non-unique) tokens from some corpus\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of { token, (count, fraction) } pairs.\n",
    "    '''\n",
    "\n",
    "    token_list = nltk.word_tokenize(content)\n",
    "    total_token_count = len(token_list)\n",
    "\n",
    "    freq_dict = nltk.FreqDist(token_list)\n",
    "\n",
    "    frac_dict = {}\n",
    "    for token, count in freq_dict.items():\n",
    "        frac_dict[token] = (count, count / total_token_count)\n",
    "\n",
    "    return frac_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/vocabbuilder.txt\") as f:\n",
    "    content = f.read().lower()\n",
    "\n",
    "token_list = nltk.word_tokenize(content.lower())\n",
    "frac_dist = get_frac_dist(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s                   :  2647, 0.00830\n",
      "silence             :     6, 0.00002\n",
      "sound               :   360, 0.00113\n",
      "thousand            :    75, 0.00024\n",
      "clench              :     1, 0.00000\n",
      "asshole             :    37, 0.00012\n",
      "have                :  1400, 0.00439\n",
      "definitely          :   225, 0.00071\n",
      "notice              :   128, 0.00040\n",
      "klein               :     2, 0.00001\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for k, v in frac_dist.items():\n",
    "\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break\n",
    "\n",
    "    token = k.lower()\n",
    "    count = v[0]\n",
    "    frac = v[1]\n",
    "    print('%-20s: %5d, %0.5f' % (token, count, frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13288\n"
     ]
    }
   ],
   "source": [
    "l = [ (k, v[0], v[1]) for k, v in frac_dist.items() if v[0] >= 2]\n",
    "print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28580"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frac_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n"
     ]
    }
   ],
   "source": [
    "print(l[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13288\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "i = 0\n",
    "for i in range(len(l)):\n",
    "    #print(word)\n",
    "    vocab.add(l[i][0])\n",
    "vocab = sorted(vocab)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/vocab_docnade.vocab\", \"w\") as f:\n",
    "    for item in vocab:\n",
    "        f.write(item + \"\\n\")\n",
    "f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datatrain = pd.read_csv(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/processed/preprocess/training.csv\") \n",
    "datatest = pd.read_csv(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/processed/preprocess/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords and only keep words that are in vocab\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = str(text)\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw= [word for word in text_tokens if not word in all_stopwords and word in vocab]\n",
    "    return tokens_without_sw\n",
    "\n",
    "sp = spacy.load('en_core_web_lg')\n",
    "all_stopwords = sp.Defaults.stop_words\n",
    "\n",
    "\n",
    "datatrain[\"text\"] = datatrain['text'].apply(remove_stopwords)\n",
    "datatest[\"text\"] = datatest['text'].apply(remove_stopwords)\n",
    "datatrain['length']=datatrain['text'].apply(len)\n",
    "datatest['length']=datatest['text'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    \"hockey\": '0',\n",
    "    \"politics\":'1',\n",
    "    \"atheism\": '2',\n",
    "    \"baseball\":'3',\n",
    "    \"Bitcoin\":'4',\n",
    "    \"Christianity\":'5',\n",
    "    \"cars\":'6',\n",
    "    \"motorcycles\":'7',\n",
    "    \"guns\":'8',\n",
    "    \"space\":'9',\n",
    "    \"DebateReligion\":'10',\n",
    "    \"worldpolitics\":'11',\n",
    "    \"GameSale\":'12',\n",
    "    \"hardware\":'13',\n",
    "    \"medicalschool\":'14',\n",
    "    \"Windows10\":'15',\n",
    "    \"mac\":'16',\n",
    "    \"graphic_design\":'17',\n",
    "    \"AskElectronics\":'18',\n",
    "    \"windows\":'19'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-98-48e55f3a8d2f>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datatrain[\"target\"][index] = label_dict[str(row[\"label\"])]\n",
      "<ipython-input-98-48e55f3a8d2f>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datatest[\"target\"][index] = label_dict[str(row[\"label\"])]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[lie, pp]</td>\n",
       "      <td>hockey</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[bold, prediction, score, tho]</td>\n",
       "      <td>hockey</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fuck, sauce, pant]</td>\n",
       "      <td>hockey</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>hockey</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>hockey</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text   label  length target\n",
       "0                       [lie, pp]  hockey       2      0\n",
       "1  [bold, prediction, score, tho]  hockey       4      0\n",
       "2             [fuck, sauce, pant]  hockey       3      0\n",
       "3                              []  hockey       0      0\n",
       "4                              []  hockey       0      0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatrain[\"target\"]=\"\"\n",
    "for index, row in datatrain.iterrows():\n",
    "    datatrain[\"target\"][index] = label_dict[str(row[\"label\"])]\n",
    "datatest[\"target\"]=\"\"\n",
    "for index, row in datatest.iterrows():\n",
    "    datatest[\"target\"][index] = label_dict[str(row[\"label\"])]    \n",
    "    \n",
    "\n",
    "datatrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[lie, pp]</td>\n",
       "      <td>hockey</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[bold, prediction, score, tho]</td>\n",
       "      <td>hockey</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fuck, sauce, pant]</td>\n",
       "      <td>hockey</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>hockey</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>hockey</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text   label  length target\n",
       "0                       [lie, pp]  hockey       2      0\n",
       "1  [bold, prediction, score, tho]  hockey       4      0\n",
       "2             [fuck, sauce, pant]  hockey       3      0\n",
       "3                              []  hockey       0      0\n",
       "4                              []  hockey       0      0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [datatrain,datatest]\n",
    "data = pd.concat(frames)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11800 8000 19800\n"
     ]
    }
   ],
   "source": [
    "print(len(datatrain),len(datatest),len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 20NGfile\n",
    "f = open(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/20NG.txt\",\"w\",encoding='utf-8')\n",
    "for index,row in data.iterrows():\n",
    "    if row[\"text\"] == []:\n",
    "        continue\n",
    "    text = \" \".join(row[\"text\"])\n",
    "    f.write(row[\"label\"]+\"\\t\"+text+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split for evaluation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data = train_test_split(datatrain, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length    13.288182\n",
      "target          inf\n",
      "dtype: float64\n",
      "length    22.331224\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data.mean(axis = 0, skipna = True))\n",
    "print(data.std(axis = 0, skipna = True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length    13.623835\n",
      "target          inf\n",
      "dtype: float64\n",
      "length    23.066024\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.mean(axis = 0, skipna = True))\n",
    "print(train_data.std(axis = 0, skipna = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length    13.717797\n",
      "target          inf\n",
      "dtype: float64\n",
      "length    22.855668\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(val_data.mean(axis = 0, skipna = True))\n",
    "print(val_data.std(axis = 0, skipna = True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length    12.765375\n",
      "target          inf\n",
      "dtype: float64\n",
      "length    21.260188\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(datatest.mean(axis = 0, skipna = True)) \n",
    "print(datatest.std(axis = 0, skipna = True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 20NG train txt\n",
    "f = open(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/20NG_train.txt\",\"w\",encoding='utf-8')\n",
    "for index,row in train_data.iterrows():\n",
    "    if row[\"text\"] == []:\n",
    "        continue\n",
    "    text = \" \".join(row[\"text\"])\n",
    "    f.write(row[\"label\"]+\"\\t\"+text+\"\\n\")\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 20NG val txt\n",
    "f = open(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/20NG_val.txt\",\"w\",encoding='utf-8')\n",
    "for index,row in val_data.iterrows():\n",
    "    if row[\"text\"] == []:\n",
    "        continue\n",
    "    text = \" \".join(row[\"text\"])\n",
    "    f.write(row[\"label\"]+\"\\t\"+text+\"\\n\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 20NG test txt\n",
    "f = open(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/20NG_test.txt\",\"w\",encoding='utf-8')\n",
    "for index,row in datatest.iterrows():\n",
    "    if row[\"text\"] == []:\n",
    "        continue\n",
    "    text = \" \".join(row[\"text\"])\n",
    "    f.write(row[\"label\"]+\"\\t\"+text+\"\\n\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 20NG text only  txt\n",
    "f = open(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/20NGTextonly.txt\",\"w\",encoding='utf-8')\n",
    "for index,row in data.iterrows():\n",
    "    if row[\"text\"] == []:\n",
    "        continue\n",
    "    text = \" \".join(row[\"text\"])\n",
    "    f.write(text+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-111-f4a64c268447>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datatestcsv[\"text\"][index] = \" \".join(row[\"text\"])\n"
     ]
    }
   ],
   "source": [
    "# test.csv\n",
    "datatestcsv = datatest.copy()\n",
    "for index,row in datatestcsv.iterrows():\n",
    "    if row[\"text\"] == []:\n",
    "        continue\n",
    "    datatestcsv[\"text\"][index] = \" \".join(row[\"text\"])\n",
    "datatestcsv.to_csv(path_or_buf=\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/test.csv\",columns=[\"label\",\"text\"],header=False,index=False,encoding=\"utf-8\",line_terminator=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-112-612cbb68a9b4>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datatraincsv[\"text\"][index] = \" \".join(row[\"text\"])\n"
     ]
    }
   ],
   "source": [
    "# training.csv\n",
    "datatraincsv = train_data.copy()\n",
    "for index,row in datatraincsv.iterrows():\n",
    "    if row[\"text\"] == []:\n",
    "        continue\n",
    "    datatraincsv[\"text\"][index] = \" \".join(row[\"text\"])\n",
    "datatraincsv.to_csv(path_or_buf=\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/training.csv\",columns=[\"label\",\"text\"],header=False,index=False,encoding=\"utf-8\",line_terminator=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-113-7591ef3a9d78>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datavalcsv[\"text\"][index] = \" \".join(row[\"text\"])\n"
     ]
    }
   ],
   "source": [
    "# validation.csv\n",
    "datavalcsv = val_data.copy()\n",
    "for index,row in datavalcsv.iterrows():\n",
    "    if row[\"text\"] == []:\n",
    "        continue\n",
    "    datavalcsv[\"text\"][index] = \" \".join(row[\"text\"])\n",
    "datavalcsv.to_csv(path_or_buf=\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/validation.csv\",columns=[\"label\",\"text\"],header=False,index=False,encoding=\"utf-8\",line_terminator=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11800 8000 19800\n"
     ]
    }
   ],
   "source": [
    "print(len(datatrain),len(datatest),len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = dict()\n",
    "i = 0\n",
    "for word in vocab:\n",
    "    word2id[word] = i\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_mapping = {v: k for k, v in label_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_docnade.xlsx\n",
    "with open(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/20NG_test.txt\", \"r\") as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip() for x in content] \n",
    "content= [x.split(\"\\t\") for x in content]\n",
    "csvfile = pd.DataFrame(content,columns=[\"label\",\"text\"])\n",
    "for index,row in csvfile.iterrows():\n",
    "    id_string = str()\n",
    "    for word in row[\"text\"].split():\n",
    "        id_string += \" \"+str(word2id[word])\n",
    "    label_id = label_dict[row[\"label\"]]    \n",
    "    csvfile[\"text\"][index] = id_string\n",
    "    csvfile[\"label\"][index] = label_id\n",
    "csvfile.to_csv(path_or_buf=\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/test_docnade.csv\",columns=[\"label\",\"text\"],header=False,index=False,encoding=\"utf-8\",line_terminator=\"\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_docnade.xlsx\n",
    "with open(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/20NG_train.txt\", \"r\") as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip() for x in content] \n",
    "content= [x.split(\"\\t\") for x in content]\n",
    "csvfile = pd.DataFrame(content,columns=[\"label\",\"text\"])\n",
    "\n",
    "for index,row in csvfile.iterrows():\n",
    "    id_string = str()\n",
    "    for word in row[\"text\"].split():\n",
    "        id_string += \" \"+str(word2id[word])\n",
    "    label_id = label_dict[row[\"label\"]]    \n",
    "    csvfile[\"text\"][index] = id_string\n",
    "    csvfile[\"label\"][index] = label_id\n",
    "csvfile.to_csv(path_or_buf=\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/training_docnade.csv\",columns=[\"label\",\"text\"],header=False,index=False,encoding=\"utf-8\",line_terminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_docnade.xlsx\n",
    "with open(\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/20NG_val.txt\", \"r\") as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip() for x in content] \n",
    "content= [x.split(\"\\t\") for x in content]\n",
    "csvfile = pd.DataFrame(content,columns=[\"label\",\"text\"])\n",
    "csvfile.head()\n",
    "for index,row in csvfile.iterrows():\n",
    "    id_string = str()\n",
    "    for word in row[\"text\"].split():\n",
    "        id_string += \" \"+str(word2id[word])\n",
    "    label_id = label_dict[row[\"label\"]]    \n",
    "    csvfile[\"text\"][index] = id_string\n",
    "    csvfile[\"label\"][index] = label_id\n",
    "csvfile.to_csv(path_or_buf=\"/home/flokla/Dropbox/Desktop/bachelorarbeit/realshit/Datasets/20subs_long/idocnade/validation_docnade.csv\",columns=[\"label\",\"text\"],header=False,index=False,encoding=\"utf-8\",line_terminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
